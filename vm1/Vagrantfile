Vagrant.configure("2") do |config|
  config.vm.box = "ubuntu/bionic64"
  config.vm.network "public_network", bridge: "wlp2s0", :mac => "000000000001"
  config.vm.provider "virtualbox" do |vb|
    vb.name = "vm1"
    vb.cpus = 2
    vb.memory = "4096"
  end
  config.vm.provision "shell", privileged: true, inline: <<-SHELL
    hostnamectl set-hostname vm1
    sed -i '/127\.0\.1\.1/d' /etc/hosts
    echo '192.168.1.101	vm1' >> /etc/hosts

    apt-get update && apt-get install -y nfs-kernel-server nfs-common pdsh
    mkdir /cluster
    chmod 777 /cluster
    echo '/cluster 192.168.1.0/24(rw,sync,no_subtree_check)' >> /etc/exports
    exportfs -a
    systemctl restart nfs-kernel-server

    tar xf /vagrant/OpenJDK8U-jdk_x64_linux_hotspot_8u232b09.tar.gz -C /opt
    ln -s /opt/jdk8u232-b09 /opt/jdk8
    echo 'JAVA_HOME=/opt/jdk8' >> /etc/environment
    echo 'HADOOP_HOME=/opt/hadoop' >> /etc/environment

    tar xf /vagrant/hadoop-3.2.1.tar.gz -C /opt
    ln -s /opt/hadoop-3.2.1 /opt/hadoop
    chown -R vagrant:vagrant /opt/hadoop-3.2.1 /opt/hadoop
    mkdir /disk1 && chown vagrant /disk1
    cp /vagrant/hadoop-conf/* /opt/hadoop/etc/hadoop

    tar xf /vagrant/spark-2.4.5-bin-hadoop2.7.tgz -C /opt
    ln -s /opt/spark-2.4.5-bin-hadoop2.7 /opt/spark
    cp /vagrant/slaves /opt/spark/conf
    cp /vagrant/spark-env.sh /opt/spark/conf
  SHELL

  config.vm.provision "shell", privileged: false, inline: <<-SHELL
    cat /vagrant/vmcluster.id_rsa.pub >> /home/vagrant/.ssh/authorized_keys
    cp /vagrant/vmcluster.id_rsa /home/vagrant/.ssh/id_rsa
    echo 'export PDSH_RCMD_TYPE=ssh' >> /home/vagrant/.profile
    echo 'export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' >> /home/vagrant/.profile
    JAVA_HOME=/opt/jdk8 /opt/hadoop/bin/hdfs namenode -format
  SHELL

end
